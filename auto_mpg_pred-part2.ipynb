{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e081827",
   "metadata": {},
   "source": [
    "# Predicting Fuel Efficiency of Vehicles - Part 2\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "\n",
    "1. Handling categorical Attributes - OneHotEncoder\n",
    "2. Data Cleaning - Imputer\n",
    "3. Attribute Addition - Adding custom transformation\n",
    "4. Setting up Data Transformation Pipeline for numerical and categorical column.\n",
    "\n",
    "We will automate app the steps and use base class to write custom transformations to add new features to the dataset, that turned out te be important to us in the last step.\n",
    "\n",
    "At the end, we would have a pipeline, and we will pass just the dataframe to that pipeline and receive the prepared data, ready to go into the ML model. Both to train and to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70aa6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing general use case libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87048132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "# Defining the column names\n",
    "cols = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "        'Acceleration','Model Year','Origin']\n",
    "\n",
    "# Loading the dataset into a dataframe\n",
    "df = pd.read_csv('auto-mpg.data',names=cols, na_values='?',\n",
    "                 comment='\\t',sep=' ',skipinitialspace=True)\n",
    "\n",
    "# Making a copy of this dataframe\n",
    "data = df.copy()\n",
    "\n",
    "# Splitting training and test datasets\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data,data['Cylinders']):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3cda2",
   "metadata": {},
   "source": [
    "As I have target variable and features in one dataframe, I will separate them.\n",
    "#### Segregating Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc9b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
       "145          4          83.0        61.0  2003.0          19.0          74   \n",
       "151          4          79.0        67.0  2000.0          16.0          74   \n",
       "388          4         156.0        92.0  2585.0          14.5          82   \n",
       "48           6         250.0        88.0  3139.0          14.5          71   \n",
       "114          4          98.0        90.0  2265.0          15.5          73   \n",
       "\n",
       "     Origin  \n",
       "145       3  \n",
       "151       2  \n",
       "388       1  \n",
       "48        1  \n",
       "114       2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = strat_train_set.drop('MPG',axis=1)\n",
    "data_labels = strat_train_set['MPG'].copy()  # Target variable\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a9167",
   "metadata": {},
   "source": [
    "We have 7 attributes we have to work with.\n",
    "\n",
    "The next function we have to implement is Preprocessing the Origin Column. We will change the codes to countries.\n",
    "\n",
    "\n",
    "#### Preprocessing the Origin Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5104fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
       "145          4          83.0        61.0  2003.0          19.0          74   \n",
       "151          4          79.0        67.0  2000.0          16.0          74   \n",
       "388          4         156.0        92.0  2585.0          14.5          82   \n",
       "48           6         250.0        88.0  3139.0          14.5          71   \n",
       "114          4          98.0        90.0  2265.0          15.5          73   \n",
       "\n",
       "      Origin  \n",
       "145  Germany  \n",
       "151      USA  \n",
       "388    India  \n",
       "48     India  \n",
       "114      USA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_origin_cols(df):\n",
    "    df['Origin'] = df['Origin'].map({1:'India', 2:'USA', 3:'Germany'})\n",
    "    return df\n",
    "\n",
    "data_tr = preprocess_origin_cols(data)\n",
    "data_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfea0a",
   "metadata": {},
   "source": [
    "### 1. One Hot Encoding the Origin Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d60d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 318 entries, 145 to 362\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Cylinders     318 non-null    int64  \n",
      " 1   Displacement  318 non-null    float64\n",
      " 2   Horsepower    314 non-null    float64\n",
      " 3   Weight        318 non-null    float64\n",
      " 4   Acceleration  318 non-null    float64\n",
      " 5   Model Year    318 non-null    int64  \n",
      " 6   Origin        318 non-null    object \n",
      "dtypes: float64(4), int64(2), object(1)\n",
      "memory usage: 19.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426944f",
   "metadata": {},
   "source": [
    "There are missing values in Horsepower column. That is alright, we will take care of it later.\n",
    "\n",
    "The data type of the Origin column is object, which means it is categorical column, a qualitative value we will have to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e246bea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Origin\n",
       "145  Germany\n",
       "151      USA\n",
       "388    India\n",
       "48     India\n",
       "114      USA"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolating all the categorical variables\n",
    "# isolating only origin as it is the only categorical variables\n",
    "data_cat = data_tr[[\"Origin\"]]\n",
    "data_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c62415a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<318x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 318 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding the categorical values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "data_cat_1hot = cat_encoder.fit_transform(data_cat)\n",
    "data_cat_1hot      # returns a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e18cba",
   "metadata": {},
   "source": [
    "We could have used get_dummies() method from pandas, but as we are automating, its better to use sklearn OneHotEncoder class which gives us a sparse matrix.\n",
    "\n",
    "First we instantiate the class OneHotEncoder. Now this instance of a class has a method called fit_tranform(<categorical_data>). This method computes the no of categories present and creates one-hot vectors for all the categories. Then it returns a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d63ce47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts the matrix into a 2D array \n",
    "data_cat_1hot.toarray()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbdee28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Germany', 'India', 'USA'], dtype=object)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tells categories it encoded to one-hot-vectors\n",
    "cat_encoder.categories_  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ed465",
   "metadata": {},
   "source": [
    "We have looked and transformed categorical variable. Now we will see how this step will be implemented with a statement in a pipeline.\n",
    "\n",
    "So, the above was for explanation for what will happen in backend. Now we will build and automate this stuff, soon. This is why we will work with original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa824d5",
   "metadata": {},
   "source": [
    "### 2. Handling Missing Values using SimpleImputer\n",
    "\n",
    "We saw we have null values. We will take care of the. \\\n",
    "Steps:\n",
    "1. We will first segregate numerical columns\n",
    "2. Used SimpleImputer class to impute missing values using medians\n",
    "3. Converted the data back to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76083b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 318 entries, 145 to 362\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Cylinders     318 non-null    int64  \n",
      " 1   Displacement  318 non-null    float64\n",
      " 2   Horsepower    314 non-null    float64\n",
      " 3   Weight        318 non-null    float64\n",
      " 4   Acceleration  318 non-null    float64\n",
      " 5   Model Year    318 non-null    int64  \n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 17.4 KB\n"
     ]
    }
   ],
   "source": [
    "# segregating the numerical columns,\n",
    "# leaving the Origin column as it is string.\n",
    "num_data = data.iloc[:,:-1]\n",
    "num_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eac0d6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# refer the documentation for examples of other strategies to impute\n",
    "imputer = SimpleImputer(strategy=\"median\")   # Note it creates an imputer object of SimpleImputer class  \n",
    "imputer.fit(num_data)      # we give data to the imputer object, and it returns fitted estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4e522f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4. ,  146. ,   92. , 2844. ,   15.5,   76. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns medians of all the 6 columns we have\n",
    "imputer.statistics_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e18ce6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4. ,  146. ,   92. , 2844. ,   15.5,   76. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use pandas dataframe to compute the median - same\n",
    "data.median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4854ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4. ,   83. ,   61. , 2003. ,   19. ,   74. ],\n",
       "       [   4. ,   79. ,   67. , 2000. ,   16. ,   74. ],\n",
       "       [   4. ,  156. ,   92. , 2585. ,   14.5,   82. ],\n",
       "       ...,\n",
       "       [   4. ,  135. ,   84. , 2295. ,   11.6,   82. ],\n",
       "       [   4. ,  113. ,   95. , 2372. ,   15. ,   70. ],\n",
       "       [   6. ,  146. ,  120. , 2930. ,   13.8,   81. ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputing the missing values by transforming the dataframe\n",
    "x = imputer.transform(num_data)  # imputes all missing values in num_data and returns imputed data in ndarray form\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99fe3478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 318 entries, 145 to 362\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Cylinders     318 non-null    float64\n",
      " 1   Displacement  318 non-null    float64\n",
      " 2   Horsepower    318 non-null    float64\n",
      " 3   Weight        318 non-null    float64\n",
      " 4   Acceleration  318 non-null    float64\n",
      " 5   Model Year    318 non-null    float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 17.4 KB\n"
     ]
    }
   ],
   "source": [
    "# converting the 2D array back into a dataframe \n",
    "# (because easier to look at dataframe)\n",
    "data_tr = pd.DataFrame(x, columns=num_data.columns, \n",
    "                       index=num_data.index)\n",
    "data_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4d301",
   "metadata": {},
   "source": [
    "Originally we had 6 missing values but here only 4 were there, 2 are in the test dataset.\n",
    "\n",
    "When we will test data, we will pre-process the test data set as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3dbc97",
   "metadata": {},
   "source": [
    "### Adding Attributes using BaseEstimator and Transformer\n",
    "\n",
    "Adding out custom attributes using BaseEstimator class.\n",
    "The BaseEstimator class allows you to define your own methods and override transform and fit_transform methods.\n",
    "\n",
    "Transformer mixin class allows you to build all sort of transformers that you want to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "771d0282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year\n",
       "145          4          83.0        61.0  2003.0          19.0          74\n",
       "151          4          79.0        67.0  2000.0          16.0          74\n",
       "388          4         156.0        92.0  2585.0          14.5          82\n",
       "48           6         250.0        88.0  3139.0          14.5          71\n",
       "114          4          98.0        90.0  2265.0          15.5          73"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8c3fbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.0000000e+00, 8.3000000e+01, 6.1000000e+01, 2.0030000e+03,\n",
       "       1.9000000e+01, 7.4000000e+01, 3.1147541e-01, 4.7500000e+00])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# column indexes of Acceleration, Horsepower, Cylinders\n",
    "acc_ix, hpower_ix, cyl_ix = 4, 2, 0\n",
    "\n",
    "class CustomAttrAdder(BaseEstimator, TransformerMixin):    # inherts BaseEstimator and TransformerMixin class, they work on ndarrays\n",
    "    def __init__(self, acc_on_power=True):                 # no *args or **kargs\n",
    "        self.acc_on_power = acc_on_power\n",
    "    def fit(self, X, y=None):\n",
    "        return self                                        # nothing else to do\n",
    "    def transform(self, X):                                # X is a 2D array\n",
    "        acc_on_cyl = X[:, acc_ix] / X[:, cyl_ix]\n",
    "        if self.acc_on_power:\n",
    "            acc_on_power = X[:, acc_ix] / X[:, hpower_ix]\n",
    "            return np.c_[X, acc_on_power, acc_on_cyl]      # concatenates arrays\n",
    "        return np.c_[X, acc_on_cyl]\n",
    "    \n",
    "\n",
    "attr_adder = CustomAttrAdder(acc_on_power=True)\n",
    "data_tr_extra_attrs = attr_adder.transform(data_tr.values)\n",
    "data_tr_extra_attrs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e5d824",
   "metadata": {},
   "source": [
    "### 4. Creating a Pipeline of tasks\n",
    "\n",
    "Currently we have seen the individual elements, now we will create pipeline, so that we only pass the data and everythings gets handled automatically and it returns the prepared data.\n",
    "\n",
    "For this we will use pipeline class from sklearn pipeline model. The other method we will add is StandardScaler. Because it is a good practice to scale the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af2ea62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.85657842, -1.07804475, -1.15192977, -1.17220298,  1.21586943,\n",
       "       -0.54436373,  1.70952741,  1.29565517])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Pipeline class\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Using StandardScalar to scale all the numerical attributes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerics = ['float64','int64']\n",
    "\n",
    "num_data = data_tr.select_dtypes(include=numerics)\n",
    "\n",
    "# pipeline for numerical attributes\n",
    "# imputing -> adding attributes -> scale them\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer',  SimpleImputer(strategy='median')),         # Task 1: Impute Missing Values\n",
    "    ('attrs_adder', CustomAttrAdder()),                     # Task 2: Add Custom Attributes\n",
    "    ('std_scaler', StandardScaler()),                       # Task 3: Scale the values\n",
    "])\n",
    "\n",
    "num_data_tr = num_pipeline.fit_transform(num_data)\n",
    "num_data_tr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654dd43",
   "metadata": {},
   "source": [
    "#### Transforming Numerical and Categorical Attributes\n",
    "\n",
    "Above we saw the processing for numerical values in the pipeline. Next, we can add categorical processing as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4d0197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85657842, -1.07804475, -1.15192977, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.85657842, -1.1174582 , -0.9900351 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.85657842, -0.3587492 , -0.31547399, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.85657842, -0.56566984, -0.53133355, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.85657842, -0.78244384, -0.23452666, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.32260746, -0.45728283,  0.44003446, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform different columns or subsets using ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attrs = list(num_data)\n",
    "cat_attrs = ['Origin']\n",
    "\n",
    "# Complete pipeline to transform\n",
    "# Both numerical and categorical attributes\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attrs),\n",
    "    ('cat', OneHotEncoder(), cat_attrs),\n",
    "])\n",
    "\n",
    "prepared_data = full_pipeline.fit_transform(data)\n",
    "prepared_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
